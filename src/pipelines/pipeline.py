import os

import streamlit as st

from langchain.callbacks.base import BaseCallbackHandler
from langchain_openai import OpenAIEmbeddings
from langgraph.graph.state import CompiledStateGraph
from langgraph.errors import GraphRecursionError

from hydra.utils import instantiate
from omegaconf import DictConfig

from ..utils.setup import SetUp
from ..workflows.sql_workflow import SQLWorkflow


OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]

st.set_page_config(
    page_title="WithPet",
    page_icon="ğŸ•",
)


class ChatCallbackHandler(BaseCallbackHandler):
    """
    LLMì´ í† í° ë‹¨ìœ„ë¡œ ì¶œë ¥í•  ë•Œë§ˆë‹¤ Streamlit UIì— ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸í•´ì£¼ëŠ” ì½œë°± í•¸ë“¤ëŸ¬ì…ë‹ˆë‹¤.
    """

    message = ""

    def on_llm_start(
        self,
        *args,
        **kwargs,
    ) -> None:
        """LLMì´ ì‹œì‘ë  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤. í† í° ëˆ„ì ìš© ë¹ˆ ì»¨í…Œì´ë„ˆë¥¼ ë§Œë“­ë‹ˆë‹¤."""
        self.message_box = st.empty()

    def on_llm_end(
        self,
        *args,
        **kwargs,
    ) -> None:
        """LLMì´ ì¢…ë£Œë  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤. ìµœì¢… ë©”ì‹œì§€ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        save_message(
            self.message,
            "ai",
        )

    def on_llm_new_token(
        self,
        token,
        *args,
        **kwargs,
    ) -> None:
        """LLMì´ ìƒˆ í† í°ì„ ìƒì„±í•  ë•Œë§ˆë‹¤ í˜¸ì¶œë©ë‹ˆë‹¤. í† í°ì„ ëˆ„ì í•´ UIì— í‘œì‹œí•©ë‹ˆë‹¤."""
        self.message += token
        self.message_box.markdown(self.message)


def save_message(
    message: str,
    role: str,
) -> None:
    """ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì— ì €ì¥í•©ë‹ˆë‹¤."""
    st.session_state["messages"].append(
        {
            "message": message,
            "role": role,
        }
    )


def send_message(
    message: str,
    role: str,
    save: bool = True,
    placeholder=None,
) -> None:
    """
    ì±„íŒ… UIì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    save=Trueì¸ ê²½ìš°, ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì—ë„ ë©”ì‹œì§€ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
    placeholderê°€ ì œê³µë˜ë©´ UI ë©”ì‹œì§€ë¥¼ ê·¸ ì•ˆì—ì„œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    if placeholder:
        placeholder.markdown(
            message
        )  # Update existing message if placeholder is provided
    else:
        with st.chat_message(role):
            st.markdown(message)  # Normal UI message if no placeholder

    if save:
        save_message(
            message,
            role,
        )


def paint_history() -> None:
    """ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì— ê¸°ë¡ëœ ë©”ì‹œì§€ë¥¼ ëª¨ë‘ ë‹¤ì‹œ ì¶œë ¥í•©ë‹ˆë‹¤."""
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    for msg in st.session_state["messages"]:
        send_message(
            msg["message"],
            msg["role"],
            save=False,
        )


@st.cache_resource
def get_embeddings(api_key: str) -> OpenAIEmbeddings:
    return OpenAIEmbeddings(openai_api_key=api_key)


def load_workflow(
    config: DictConfig,
    stream: bool = True,
) -> CompiledStateGraph:

    chat_callback_handler = ChatCallbackHandler()
    embeddings = get_embeddings(api_key=config.openai_api_key)

    setup = SetUp(config)

    llm = setup.get_llm()
    llm_stream = setup.get_llm_stream(chat_callback_handler) if stream else llm
    conn = setup.get_connection()
    vs_example = setup.get_vs_example(embeddings=embeddings)
    if os.path.exists(config.vector_store_data):
        vs_data = setup.get_vs_data(embeddings=embeddings)
    else:
        vs_data = None

    context = setup.get_context(
        llm=llm,
        llm_stream=llm_stream,
        conn=conn,
        vs_example=vs_example,
        vs_data=vs_data,
    )

    source_routing_template = setup.get_prompt_template(
        prompt_type=config.prompt_type.source_routing_template
    )
    sql_generation_template = setup.get_prompt_template(
        prompt_type=config.prompt_type.sql_generation_template
    )
    source_columns = setup.get_source_columns()
    answer_generation_template = setup.get_prompt_template(
        prompt_type=config.prompt_type.answer_generation_template
    )

    workflow = SQLWorkflow(
        context=context,
        source_routing_template=source_routing_template,
        schemas=config.schemas,
        sql_generation_template=sql_generation_template,
        source_columns=source_columns,
        answer_generation_template=answer_generation_template,
    )

    app = workflow.setup_workflow()
    return app


def pipeline(
    config: DictConfig,
) -> None:

    app = load_workflow(
        config=config,
        stream=True,
    )

    st.markdown(
        """
        <h2 style='text-align: center; color: #FF914D;'>
            ğŸ¾ WithPet: ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ì‹œì„¤ ê°€ì´ë“œ ğŸ¾
        </h2>
        """,
        unsafe_allow_html=True,
    )

    st.markdown(
        """
        <p style="text-align: center; font-size: 18px; color: #555; font-weight: bold;">
            ë°˜ë ¤ë™ë¬¼ê³¼ í•¨ê»˜ í•  ìˆ˜ ìˆëŠ” ì¥ì†Œë¥¼ ì°¾ì•„ë³´ì„¸ìš”! ğŸ¶ğŸ±
        </p>
        """,
        unsafe_allow_html=True,
    )

    st.markdown(
        """
        <div style="
            background-color: #FFF3E6;
            padding: 15px;
            border-radius: 10px;
            box-shadow: 2px 2px 10px rgba(0,0,0,0.1);
        ">
            <h5 style="color: #FF6B00;">ğŸ’¡ ì´ìš© ê°€ëŠ¥í•œ ì§ˆë¬¸ ì˜ˆì‹œ</h5>
            <ul style="font-size: 16px; color: #333;">
                <li>ğŸ¥ <b>ê°•ë‚¨êµ¬ ì‹ ì‚¬ë™</b>ì— <b>ì¼ìš”ì¼ ì˜¤í›„ 1ì‹œì—</b> ì˜ì—…í•˜ëŠ” <b>ë™ë¬¼ë³‘ì›</b>ì´ ìˆë‚˜ìš”?</li>
                <li>â˜• <b>ë¶€ì‚° ë™êµ¬</b>ì— <b>ì£¼ì°¨ ê°€ëŠ¥</b>í•œ <b>ì¹´í˜</b>ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.</li>
                <li>ğŸ¡ <b>ì¸ì²œ</b>ì— ìˆëŠ” <b>ë°˜ë ¤ë™ë¬¼ ì¶”ê°€ ìš”ê¸ˆ ì—†ëŠ” íœì…˜</b> ì°¾ì•„ì¤˜.</li>
                <li>âœ‚ï¸ <b>ì¢…ë¡œêµ¬</b>ì—ì„œ <b>ì €ë… 7ì‹œ</b>ì— <b>ë¯¸ìš©</b> ê°€ëŠ¥í•œ ê³³</li>
            </ul>
        </div>
        """,
        unsafe_allow_html=True,
    )
    st.markdown(
        """
        <div>
            <p style="font-size: 14px; color: #666; text-align: center; margin-top: 15px;">
                <i>â€» í•´ë‹¹ ì±—ë´‡ì´ ì œê³µí•˜ëŠ” ëª¨ë“  ì‹œì„¤ì€ ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ê°€ëŠ¥ ì‹œì„¤ì…ë‹ˆë‹¤.</i>
            </p>
        </div>
        <br>
        """,
        unsafe_allow_html=True,
    )

    # Initialize session state for user selections
    if "selected_category" not in st.session_state:
        st.session_state.selected_category = "ì¹´í˜"

    # Initialize session state list for selected options
    if "selected_options" not in st.session_state:
        st.session_state.selected_options = []

    # Sidebar Design
    with st.sidebar:

        # Use `st.form` to prevent auto-rerun for filters
        with st.form("filter_form"):
            st.markdown(
                """
                <h1 style="display: flex; justify-content: left; align-items: center;">
                    ğŸš€ Quick Search 
                    <span style="font-size: 12px; vertical-align: sub; margin-left: 8px; cursor: pointer;" 
                        title="ì§€ì—­ê³¼ ì‹œì„¤ ìœ í˜•ì„ ì„ íƒí•œ í›„ ê²€ìƒ‰í•˜ê¸°ë¥¼ í´ë¦­í•˜ì„¸ìš”.">
                        â„¹ï¸
                    </span>
                </h1>
                <br>
                """,
                unsafe_allow_html=True,
            )

            st.markdown("### ğŸ“ ì§€ì—­")
            city = st.selectbox(
                "ì§€ì—­ ì„ íƒ",
                [
                    "ì„œìš¸",
                    "ë¶€ì‚°",
                    "ì¸ì²œ",
                    "ëŒ€êµ¬",
                    "ëŒ€ì „",
                    "ê´‘ì£¼",
                    "ìš¸ì‚°",
                    "ì„¸ì¢…",
                    "ì œì£¼",
                ],
                label_visibility="collapsed",
            )
            st.markdown("### ğŸ  ì‹œì„¤ ìœ í˜•")
            category = st.radio(
                "ì‹œì„¤ ìœ í˜•",  # Empty label to remove space
                [
                    "â˜• ì¹´í˜",
                    "ğŸ¡ íœì…˜",
                    "ğŸ¥ ë™ë¬¼ë³‘ì›",
                    "ğŸ’Š ë™ë¬¼ì•½êµ­",
                    "âœ‚ï¸ ë¯¸ìš©",
                    "ğŸ›’ ë°˜ë ¤ë™ë¬¼ìš©í’ˆ",
                    "ğŸ¢ ìœ„íƒê´€ë¦¬",
                ],
                index=[
                    "ì¹´í˜",
                    "íœì…˜",
                    "ë™ë¬¼ë³‘ì›",
                    "ë™ë¬¼ì•½êµ­",
                    "ë¯¸ìš©",
                    "ë°˜ë ¤ë™ë¬¼ìš©í’ˆ",
                    "ìœ„íƒê´€ë¦¬",
                ].index(st.session_state.selected_category),
                label_visibility="collapsed",
            )

            checkbox_options = {
                "ğŸš— ì£¼ì°¨ ê°€ëŠ¥": "ì£¼ì°¨ ê°€ëŠ¥",
                "ğŸ—“ï¸ ì£¼ë§ ìš´ì˜": "ì£¼ë§ ìš´ì˜",
                "â° 24ì‹œê°„ ìš´ì˜": "24ì‹œê°„ ìš´ì˜",
                "â›… ì•„ì¹¨ 9ì‹œ ì´ì „ ì˜ì—…": "ì•„ì¹¨ 9ì‹œ ì´ì „ ì˜ì—…",
                "ğŸŒ™ ë°¤ 10ì‹œ ì´í›„ ì˜ì—…": "ë°¤ 10ì‹œ ì´í›„ ì˜ì—…",
                "ğŸª™ ë°˜ë ¤ë™ë¬¼ ì¶”ê°€ ìš”ê¸ˆ ì—†ìŒ": "ë°˜ë ¤ë™ë¬¼ ì¶”ê°€ ìš”ê¸ˆ ì—†ìŒ",
                "ğŸˆ ë°˜ë ¤ë™ë¬¼ í¬ê¸° ì œí•œ ì—†ìŒ": "ë°˜ë ¤ë™ë¬¼ í¬ê¸° ì œí•œ ì—†ìŒ",
            }
            st.markdown("### ğŸ” ì¶”ê°€ ì˜µì…˜")
            selected_values = set(st.session_state.selected_options)
            for label, key in checkbox_options.items():
                if st.checkbox(label, value=key in selected_values):
                    selected_values.add(key)  # Add selected option
                else:
                    selected_values.discard(key)  # Remove unselected option

            st.markdown("<br>", unsafe_allow_html=True)
            submitted = st.form_submit_button("ğŸ” ê²€ìƒ‰í•˜ê¸°")

            if submitted:
                st.session_state.selected_category = category.split()[1]
                st.session_state.selected_options = list(selected_values)

                category = st.session_state.selected_category
                options = st.session_state.selected_options
                options_text = f" ({', '.join(options)})" if options else ""

                query_text = f"{city} ì§€ì—­ì˜ {category}{options_text}"

                st.session_state.inputs = {"question": query_text}
                st.session_state.trigger_search = True  # Flag to trigger app invoke

    paint_history()

    # Chat Input
    message = st.chat_input("ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ì‹œì„¤ì— ëŒ€í•´ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”...")

    if message:
        st.session_state.inputs = {"question": message}
        st.session_state.trigger_search = True  # Flag to trigger app invoke

    # Process the request if search was triggered
    if st.session_state.get("trigger_search", False):
        send_message(
            st.session_state.inputs["question"],
            "human",
        )

        with st.chat_message("ai"):
            placeholder = st.empty()
            placeholder.markdown(
                "âŒ›ì§ˆë¬¸ì— í•´ë‹¹í•˜ëŠ” ì¥ì†Œë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."
            )
        try:
            response = app.invoke(
                st.session_state.inputs,
                {"recursion_limit": 10},
            )
            if (
                response["data_source"] == "not_relevant"
                or response["sql_status"] == "no data"
            ):
                send_message(
                    response["answer"],
                    "ai",
                    placeholder,
                )
        except GraphRecursionError:
            send_message(
                "ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "ai",
                placeholder,
            )

        # Reset trigger after processing
        st.session_state.trigger_search = False
        st.rerun()
